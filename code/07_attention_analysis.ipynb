{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T05:19:09.254707Z",
     "start_time": "2026-02-18T05:19:09.251138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "id": "63633c7d24b3c298",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T05:19:19.665748Z",
     "start_time": "2026-02-18T05:19:18.508493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch_geometric\n",
    "from torch_geometric.nn import RGATConv\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "import networkx as nx\n"
   ],
   "id": "5b43403c95360061",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T05:19:30.549495Z",
     "start_time": "2026-02-18T05:19:30.539734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ensure_dir(path: Path):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_yaml(path: Path):\n",
    "    import yaml\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def load_json(path: Path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(obj, path: Path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def find_project_root(start: Path = None) -> Path:\n",
    "    if start is None:\n",
    "        start = Path.cwd()\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"code\").exists() and (p / \"data\").exists() and (p / \"output\").exists():\n",
    "            return p\n",
    "    return start\n"
   ],
   "id": "dd6c33874261fec6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T05:19:43.768794Z",
     "start_time": "2026-02-18T05:19:43.761092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_root = find_project_root()\n",
    "project_root\n"
   ],
   "id": "7dde63cb9343eccf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Shiraz University/HomeWorks/Ostad Moosavi/LinkPrediction')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T05:19:53.509449Z",
     "start_time": "2026-02-18T05:19:53.298786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_path = project_root / \"code\" / \"config.yaml\"\n",
    "cfg = load_yaml(config_path)\n",
    "\n",
    "proc_dir = project_root / cfg[\"data\"][\"processed_dir\"]\n",
    "out_dir  = project_root / cfg[\"output\"][\"dir\"]\n",
    "\n",
    "fig_dir = out_dir / \"figures\"\n",
    "sub_dir = out_dir / \"subgraphs\"\n",
    "met_dir = out_dir / \"metrics\"\n",
    "\n",
    "ensure_dir(fig_dir)\n",
    "ensure_dir(sub_dir)\n",
    "ensure_dir(met_dir)\n",
    "\n",
    "print(\"proc_dir:\", proc_dir)\n",
    "print(\"out_dir :\", out_dir)\n"
   ],
   "id": "55434508767dc20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proc_dir: D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\data\\processed\n",
      "out_dir : D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\output\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T05:20:21.616011Z",
     "start_time": "2026-02-18T05:20:20.759497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load graph + maps\n",
    "g = torch.load(proc_dir / \"graph_edges.pt\")\n",
    "\n",
    "edge_index = g[\"edge_index\"]\n",
    "edge_type  = g[\"edge_type\"]\n",
    "num_nodes  = int(g[\"num_nodes\"])\n",
    "num_relations = int(g[\"num_relations\"])\n",
    "\n",
    "id2entity = load_json(proc_dir / \"id2entity.json\")\n",
    "id2relation = load_json(proc_dir / \"id2relation.json\")\n",
    "\n",
    "print(\"num_nodes:\", num_nodes)\n",
    "print(\"num_relations:\", num_relations)\n",
    "print(\"edges:\", edge_index.size(1))\n",
    "\n",
    "# train-graph edges (remove val/test target edges)\n",
    "keep_idx = np.load(proc_dir / \"train_graph_edge_idx.npy\")\n",
    "\n",
    "def filter_edges_by_idx(edge_index, edge_type, keep_idx):\n",
    "    keep_idx_t = torch.tensor(keep_idx, dtype=torch.long)\n",
    "    return edge_index[:, keep_idx_t], edge_type[keep_idx_t]\n",
    "\n",
    "ei_train, et_train = filter_edges_by_idx(edge_index, edge_type, keep_idx)\n",
    "print(\"train edges:\", ei_train.size(1))\n"
   ],
   "id": "5af3a01529ec8012",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes: 37614\n",
      "num_relations: 107\n",
      "edges: 118308\n",
      "train edges: 118233\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T05:20:36.049830Z",
     "start_time": "2026-02-18T05:20:36.037716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# models\n",
    "class MLPLinkScorer(nn.Module):\n",
    "    def __init__(self, dim: int, hidden: int = 128, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim * 2, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, z, heads, tails):\n",
    "        x = torch.cat([z[heads], z[tails]], dim=1)\n",
    "        return self.mlp(x).view(-1)\n",
    "\n",
    "class RGATEncoder(nn.Module):\n",
    "    def __init__(self, num_nodes, num_relations, dim=32, heads=2, dropout=0.2, num_bases=8):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_nodes, dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.conv1 = RGATConv(\n",
    "            in_channels=dim,\n",
    "            out_channels=dim,\n",
    "            num_relations=num_relations,\n",
    "            heads=heads,\n",
    "            concat=True,\n",
    "            dropout=dropout,\n",
    "            num_bases=num_bases,\n",
    "        )\n",
    "        self.conv2 = RGATConv(\n",
    "            in_channels=dim * heads,\n",
    "            out_channels=dim,\n",
    "            num_relations=num_relations,\n",
    "            heads=1,\n",
    "            concat=False,\n",
    "            dropout=dropout,\n",
    "            num_bases=num_bases,\n",
    "        )\n",
    "\n",
    "    def forward(self, edge_index, edge_type, return_attention=False):\n",
    "        x = self.emb.weight\n",
    "        if return_attention:\n",
    "            x, att1 = self.conv1(x, edge_index, edge_type, return_attention_weights=True)\n",
    "        else:\n",
    "            x = self.conv1(x, edge_index, edge_type)\n",
    "            att1 = None\n",
    "\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        if return_attention:\n",
    "            x, att2 = self.conv2(x, edge_index, edge_type, return_attention_weights=True)\n",
    "            return x, att1, att2\n",
    "\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x\n"
   ],
   "id": "f0b8a4cbf6947cb2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T05:27:13.371119Z",
     "start_time": "2026-02-18T05:27:12.956603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load rgat checkpoint (safe: infer dim/heads/bases from state_dict)\n",
    "ckpt_path = out_dir / \"models\" / \"rgat.pt\"\n",
    "if not ckpt_path.exists():\n",
    "    raise FileNotFoundError(f\"rgat checkpoint not found: {ckpt_path}\")\n",
    "\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "sd_enc = ckpt[\"encoder\"]\n",
    "\n",
    "dim_ckpt = int(sd_enc[\"emb.weight\"].shape[1])\n",
    "heads_ckpt = int(sd_enc[\"conv1.q\"].shape[1]) if \"conv1.q\" in sd_enc else int(cfg[\"model\"].get(\"rgat_heads\", 2))\n",
    "num_bases_ckpt = int(sd_enc[\"conv1.basis\"].shape[0]) if \"conv1.basis\" in sd_enc else int(cfg[\"model\"].get(\"rgat_num_bases\", 8))\n",
    "\n",
    "dropout = float(cfg[\"model\"].get(\"dropout\", 0.2))\n",
    "hidden = int(ckpt.get(\"cfg\", cfg).get(\"model\", {}).get(\"mlp_hidden\", cfg[\"model\"].get(\"mlp_hidden\", 128)))\n",
    "\n",
    "encoder = RGATEncoder(num_nodes=num_nodes,\n",
    "                      num_relations=num_relations,\n",
    "                      dim=dim_ckpt,\n",
    "                      heads=heads_ckpt,\n",
    "                      dropout=dropout,\n",
    "                      num_bases=num_bases_ckpt)\n",
    "scorer = MLPLinkScorer(dim=dim_ckpt, hidden=hidden, dropout=dropout)\n",
    "\n",
    "encoder.load_state_dict(ckpt[\"encoder\"], strict=True)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and cfg[\"train\"].get(\"use_cuda\", True) else \"cpu\")\n",
    "encoder.to(device)\n",
    "scorer.to(device)\n",
    "\n",
    "ei_train = ei_train.to(device)\n",
    "et_train = et_train.to(device)\n",
    "\n",
    "encoder.eval()\n",
    "print(\"loaded rgat:\", ckpt_path.name, \"| dim:\", dim_ckpt, \"| heads:\", heads_ckpt, \"| bases:\", num_bases_ckpt, \"| device:\", device)\n"
   ],
   "id": "9592dd25d2bb1c26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded rgat: rgat.pt | dim: 32 | heads: 2 | bases: 8 | device: cpu\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T05:27:17.685486Z",
     "start_time": "2026-02-18T05:27:16.220264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# extract attention (layer1)\n",
    "@torch.no_grad()\n",
    "def get_edge_attention(encoder, edge_index, edge_type):\n",
    "    z, att1, att2 = encoder(edge_index, edge_type, return_attention=True)\n",
    "\n",
    "    # att1, att2: (edge_index_used, alpha)\n",
    "    eidx_used, alpha = att1\n",
    "    if alpha.dim() == 2:\n",
    "        w = alpha.mean(dim=1)\n",
    "    else:\n",
    "        w = alpha.view(-1)\n",
    "\n",
    "    return w.detach().cpu().numpy()\n",
    "\n",
    "w_all = get_edge_attention(encoder, ei_train, et_train)\n",
    "\n",
    "E = int(ei_train.size(1))\n",
    "if len(w_all) >= E:\n",
    "    w = w_all[:E]\n",
    "else:\n",
    "    # fallback: pad\n",
    "    w = np.pad(w_all, (0, E - len(w_all)), constant_values=np.mean(w_all) if len(w_all) > 0 else 0.0)\n",
    "\n",
    "et_cpu = et_train.detach().cpu().numpy()\n",
    "print(\"w:\", w.shape, \"| et:\", et_cpu.shape)\n",
    "print(\"w stats:\", float(np.min(w)), float(np.mean(w)), float(np.max(w)))\n"
   ],
   "id": "9c00e6b6f0468416",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: (118233,) | et: (118233,)\n",
      "w stats: 0.0011619306169450283 0.25422683358192444 1.0\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T05:27:21.705480Z",
     "start_time": "2026-02-18T05:27:20.478325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# relation-level attention stats + plot\n",
    "topk = int(cfg.get(\"attention\", {}).get(\"topk_relations_plot\", 20))\n",
    "\n",
    "rel_sum = {}\n",
    "rel_cnt = {}\n",
    "for rid, wi in zip(et_cpu.tolist(), w.tolist()):\n",
    "    rel_sum[rid] = rel_sum.get(rid, 0.0) + float(wi)\n",
    "    rel_cnt[rid] = rel_cnt.get(rid, 0) + 1\n",
    "\n",
    "rows = []\n",
    "for rid in rel_sum:\n",
    "    avg = rel_sum[rid] / max(1, rel_cnt[rid])\n",
    "    name = id2relation.get(str(rid), f\"rel_{rid}\")\n",
    "    rows.append((rid, name, avg, rel_cnt[rid]))\n",
    "\n",
    "df_rel = pd.DataFrame(rows, columns=[\"relation_id\", \"relation_name\", \"avg_attention\", \"count\"])\n",
    "df_rel = df_rel.sort_values(\"avg_attention\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "csv_path = met_dir / \"attention_by_relation.csv\"\n",
    "df_rel.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "print(\"saved:\", csv_path)\n",
    "\n",
    "# plot topk\n",
    "top = df_rel.head(topk).copy()\n",
    "labels = top[\"relation_name\"].tolist()\n",
    "vals = top[\"avg_attention\"].tolist()\n",
    "labels = [s if len(s) <= 45 else (s[:45] + \"...\") for s in labels]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(vals)), vals)\n",
    "plt.xticks(range(len(vals)), labels, rotation=70, ha=\"right\")\n",
    "plt.title(\"Average Attention by Relation (Top)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_path = fig_dir / \"attention_by_relation.png\"\n",
    "plt.savefig(fig_path, dpi=200)\n",
    "plt.close()\n",
    "print(\"saved:\", fig_path)\n"
   ],
   "id": "c636775be14925a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\output\\metrics\\attention_by_relation.csv\n",
      "saved: D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\output\\figures\\attention_by_relation.png\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T05:27:33.181301Z",
     "start_time": "2026-02-18T05:27:31.202134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# case studies: k-hop subgraphs (edge width ~ attention)\n",
    "spl_path = proc_dir / \"split_target_edges.npz\"\n",
    "if not spl_path.exists():\n",
    "    print(\"split_target_edges.npz not found -> skip subgraphs\")\n",
    "else:\n",
    "    spl = np.load(spl_path)\n",
    "    test_pos = spl[\"test_pos\"]  # [2, N]\n",
    "    num_cases = int(cfg.get(\"attention\", {}).get(\"num_cases\", 3))\n",
    "    k_hops = int(cfg.get(\"attention\", {}).get(\"k_hops\", 2))\n",
    "\n",
    "    set_seed(int(cfg.get(\"seed\", 42)))\n",
    "    rng = np.random.default_rng(int(cfg.get(\"seed\", 42)))\n",
    "\n",
    "    if test_pos.shape[1] == 0:\n",
    "        print(\"no test positives -> skip\")\n",
    "    else:\n",
    "        picks = rng.choice(test_pos.shape[1], size=min(num_cases, test_pos.shape[1]), replace=False)\n",
    "\n",
    "        # for k_hop_subgraph edge_mask, we need CPU edge_index\n",
    "        ei_cpu = ei_train.detach().cpu()\n",
    "        et_cpu_t = et_train.detach().cpu()\n",
    "\n",
    "        for ci, j in enumerate(picks, start=1):\n",
    "            src = int(test_pos[0, j])\n",
    "            dst = int(test_pos[1, j])\n",
    "\n",
    "            subset, sub_ei, mapping, edge_mask = k_hop_subgraph(\n",
    "                [src, dst],\n",
    "                num_hops=k_hops,\n",
    "                edge_index=ei_cpu,\n",
    "                relabel_nodes=True,\n",
    "                num_nodes=num_nodes\n",
    "            )\n",
    "\n",
    "            # attention for subgraph edges (aligned with input edge list)\n",
    "            mask_np = edge_mask.detach().cpu().numpy()\n",
    "            w_sub = w[mask_np]\n",
    "            et_sub = et_cpu_t.detach().cpu().numpy()[mask_np]\n",
    "\n",
    "            # build nx graph\n",
    "            Gnx = nx.DiGraph()\n",
    "            subset_np = subset.detach().cpu().numpy().tolist()\n",
    "            sub_ei_np = sub_ei.detach().cpu().numpy()\n",
    "\n",
    "            for new_id, old_id in enumerate(subset_np):\n",
    "                lab = id2entity.get(str(old_id), str(old_id))\n",
    "                if len(lab) > 35:\n",
    "                    lab = lab[:35] + \"...\"\n",
    "                Gnx.add_node(new_id, label=lab)\n",
    "\n",
    "            widths = []\n",
    "            for e in range(sub_ei_np.shape[1]):\n",
    "                u = int(sub_ei_np[0, e]); v = int(sub_ei_np[1, e])\n",
    "                rid = int(et_sub[e]) if e < len(et_sub) else -1\n",
    "                rel = id2relation.get(str(rid), f\"r{rid}\")\n",
    "                Gnx.add_edge(u, v, weight=float(w_sub[e]), relation=rel)\n",
    "                widths.append(float(w_sub[e]))\n",
    "\n",
    "            widths = np.array(widths, dtype=float) if len(widths) > 0 else np.array([0.0])\n",
    "            if len(widths) > 0:\n",
    "                wmin, wmax = float(widths.min()), float(widths.max())\n",
    "                widths = 0.7 + 4.0 * (widths - wmin) / (wmax - wmin + 1e-9)\n",
    "            widths = widths.tolist()\n",
    "\n",
    "            plt.figure(figsize=(10, 7))\n",
    "            pos = nx.spring_layout(Gnx, seed=1)\n",
    "\n",
    "            nx.draw_networkx_nodes(Gnx, pos, node_size=400)\n",
    "            nx.draw_networkx_edges(Gnx, pos, width=widths, arrows=True, alpha=0.8)\n",
    "            nx.draw_networkx_labels(Gnx, pos, labels={n: Gnx.nodes[n][\"label\"] for n in Gnx.nodes()}, font_size=7)\n",
    "\n",
    "            plt.title(f\"Case {ci}: {k_hops}-hop subgraph (edge width ~ attention)\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "            out_path = sub_dir / f\"case_{ci:03d}.png\"\n",
    "            plt.savefig(out_path, dpi=200)\n",
    "            plt.close()\n",
    "            print(\"saved subgraph:\", out_path)\n"
   ],
   "id": "f620c2eeaafb6504",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved subgraph: D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\output\\subgraphs\\case_001.png\n",
      "saved subgraph: D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\output\\subgraphs\\case_002.png\n",
      "saved subgraph: D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\output\\subgraphs\\case_003.png\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T05:27:39.205574Z",
     "start_time": "2026-02-18T05:27:39.197479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save a short summary json for report\n",
    "summary = {\n",
    "    \"rgat_checkpoint\": str((out_dir / \"models\" / \"rgat.pt\").as_posix()),\n",
    "    \"dim\": dim_ckpt,\n",
    "    \"heads\": heads_ckpt,\n",
    "    \"num_bases\": num_bases_ckpt,\n",
    "    \"topk\": int(cfg.get(\"attention\", {}).get(\"topk_relations_plot\", 20)),\n",
    "    \"generated_files\": {\n",
    "        \"figure_attention_by_relation\": str((fig_dir / \"attention_by_relation.png\").as_posix()),\n",
    "        \"csv_attention_by_relation\": str((met_dir / \"attention_by_relation.csv\").as_posix()),\n",
    "    },\n",
    "}\n",
    "\n",
    "save_json(summary, met_dir / \"attention_summary.json\")\n",
    "print(\"saved:\", met_dir / \"attention_summary.json\")\n"
   ],
   "id": "96eba17d5d567b40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\output\\metrics\\attention_summary.json\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
