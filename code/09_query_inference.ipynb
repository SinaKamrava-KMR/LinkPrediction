{
 "cells": [
  {
   "cell_type": "code",
   "id": "cea76a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:42.945468Z",
     "start_time": "2026-02-18T08:21:42.941943Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import os, json, difflib, time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "927fdcc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:42.962138Z",
     "start_time": "2026-02-18T08:21:42.952857Z"
    }
   },
   "source": [
    "def ensure_dir(path: Path):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_yaml(path: Path):\n",
    "    import yaml\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def load_json(path: Path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def find_project_root(start: Path = None) -> Path:\n",
    "    if start is None:\n",
    "        start = Path.cwd()\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"code\").exists() and (p / \"data\").exists() and (p / \"output\").exists():\n",
    "            return p\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"code\").exists() and (p / \"data\").exists():\n",
    "            return p\n",
    "    return start\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "bdbb3cab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:42.977226Z",
     "start_time": "2026-02-18T08:21:42.968665Z"
    }
   },
   "source": [
    "project_root = find_project_root()\n",
    "os.chdir(project_root)\n",
    "print(\"CWD:\", Path.cwd())\n",
    "\n",
    "config_path = project_root / \"code\" / \"config.yaml\"\n",
    "cfg = load_yaml(config_path)\n",
    "\n",
    "proc_dir = project_root / cfg[\"data\"][\"processed_dir\"]\n",
    "out_dir  = project_root / cfg[\"output\"][\"dir\"]\n",
    "\n",
    "models_dir  = out_dir / \"models\"\n",
    "queries_dir = out_dir / \"queries\"\n",
    "ensure_dir(queries_dir)\n",
    "\n",
    "print(\"proc_dir  :\", proc_dir)\n",
    "print(\"out_dir   :\", out_dir)\n",
    "print(\"models_dir:\", models_dir, \"| exists:\", models_dir.exists())\n",
    "print(\"queries_dir:\", queries_dir)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\n",
      "proc_dir  : D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\data\\processed\n",
      "out_dir   : D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\output\n",
      "models_dir: D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\output\\models | exists: True\n",
      "queries_dir: D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\output\\queries\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "623ccbc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:43.017826Z",
     "start_time": "2026-02-18T08:21:42.984963Z"
    }
   },
   "source": [
    "g_path = proc_dir / \"graph_edges.pt\"\n",
    "if not g_path.exists():\n",
    "    raise FileNotFoundError(f\"graph_edges.pt not found: {g_path}\")\n",
    "\n",
    "g = torch.load(g_path, map_location=\"cpu\")\n",
    "edge_index = g[\"edge_index\"]   # [2, E]\n",
    "edge_type  = g[\"edge_type\"]    # [E]\n",
    "num_nodes  = int(g[\"num_nodes\"])\n",
    "num_relations = int(g[\"num_relations\"])\n",
    "\n",
    "print(\"num_nodes:\", num_nodes, \" | num_relations:\", num_relations, \" | E:\", edge_index.shape[1])\n",
    "\n",
    "id2entity   = load_json(proc_dir / \"id2entity.json\")\n",
    "id2relation = load_json(proc_dir / \"id2relation.json\")\n",
    "\n",
    "entity2id = {v: int(k) for k, v in id2entity.items()}\n",
    "\n",
    "print(\"sample entity:\", list(entity2id.items())[:3])\n",
    "print(\"sample relation:\", list(id2relation.items())[:3])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes: 37614  | num_relations: 107  | E: 118308\n",
      "sample entity: [('Gene::3313', 0), ('Gene::5521', 1), ('Compound::DB11767', 2)]\n",
      "sample relation: [('0', 'Hetionet::GiG::Gene:Gene'), ('1', 'DRUGBANK::ddi-interactor-in::Compound:Compound'), ('2', 'GNBR::Ud::Gene:Disease')]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "561c4c43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:43.186880Z",
     "start_time": "2026-02-18T08:21:43.025457Z"
    }
   },
   "source": [
    "keep_path = proc_dir / \"train_graph_edge_idx.npy\"\n",
    "if keep_path.exists():\n",
    "    keep_idx = np.load(keep_path).astype(np.int64)\n",
    "    keep_idx = keep_idx[keep_idx < edge_index.shape[1]]\n",
    "    ei_train = edge_index[:, keep_idx]\n",
    "    et_train = edge_type[keep_idx]\n",
    "    print(\"Using TRAIN graph:\", ei_train.shape, et_train.shape)\n",
    "else:\n",
    "    ei_train = edge_index\n",
    "    et_train = edge_type\n",
    "    print(\"Using FULL graph:\", ei_train.shape, et_train.shape)\n",
    "\n",
    "ei_np = ei_train.numpy()\n",
    "et_np = et_train.numpy()\n",
    "adj = [[] for _ in range(num_nodes)]\n",
    "for i in range(ei_np.shape[1]):\n",
    "    u = int(ei_np[0, i]); v = int(ei_np[1, i]); r = int(et_np[i])\n",
    "    adj[u].append((v, r))\n",
    "\n",
    "print(\"Adj built.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TRAIN graph: torch.Size([2, 118233]) torch.Size([118233])\n",
      "Adj built.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "54cf2348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:43.213364Z",
     "start_time": "2026-02-18T08:21:43.198198Z"
    }
   },
   "source": [
    "try:\n",
    "    from torch_geometric.nn import GATConv, RGCNConv, RGATConv\n",
    "except Exception as e:\n",
    "    raise ImportError(\"torch_geometric is not installed. Install it first, then rerun.\") from e\n",
    "\n",
    "\n",
    "class MLPLinkScorer(nn.Module):\n",
    "    \"\"\"Flexible MLP scorer. in_mult is inferred from checkpoint (2 or 3 or 4).\"\"\"\n",
    "    def __init__(self, dim: int, hidden: int = 128, dropout: float = 0.2, in_mult: int = 2):\n",
    "        super().__init__()\n",
    "        self.dim = int(dim)\n",
    "        self.in_mult = int(in_mult)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(self.dim * self.in_mult, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor, heads: torch.Tensor, tails: torch.Tensor) -> torch.Tensor:\n",
    "        h = z[heads]\n",
    "        t = z[tails]\n",
    "        if self.in_mult == 2:\n",
    "            x = torch.cat([h, t], dim=1)\n",
    "        elif self.in_mult == 3:\n",
    "            x = torch.cat([h, t, h * t], dim=1)\n",
    "        elif self.in_mult == 4:\n",
    "            x = torch.cat([h, t, torch.abs(h - t), h * t], dim=1)\n",
    "        else:\n",
    "            x = torch.cat([h, t], dim=1)\n",
    "        return self.net(x).view(-1)\n",
    "\n",
    "\n",
    "class GATEncoder(nn.Module):\n",
    "    def __init__(self, num_nodes, dim=64, heads=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_nodes, dim)\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = GATConv(dim, dim, heads=heads, dropout=dropout, concat=True)\n",
    "        self.conv2 = GATConv(dim * heads, dim, heads=1, dropout=dropout, concat=False)\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        x = self.emb.weight\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RGCNEncoder(nn.Module):\n",
    "    def __init__(self, num_nodes, num_relations, dim=128, dropout=0.2, num_bases=None):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_nodes, dim)\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = RGCNConv(dim, dim, num_relations, num_bases=num_bases)\n",
    "        self.conv2 = RGCNConv(dim, dim, num_relations, num_bases=num_bases)\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = self.emb.weight\n",
    "        x = self.conv1(x, edge_index, edge_type)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RGATEncoder(nn.Module):\n",
    "    def __init__(self, num_nodes, num_relations, dim=32, heads=2, dropout=0.2, num_bases=8):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_nodes, dim)\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = RGATConv(dim, dim, num_relations=num_relations, heads=heads, concat=True,\n",
    "                              dropout=dropout, num_bases=num_bases)\n",
    "        self.conv2 = RGATConv(dim * heads, dim, num_relations=num_relations, heads=1, concat=False,\n",
    "                              dropout=dropout, num_bases=num_bases)\n",
    "\n",
    "    def forward(self, edge_index, edge_type, return_attention=False):\n",
    "        x = self.emb.weight\n",
    "        if return_attention:\n",
    "            x, att1 = self.conv1(x, edge_index, edge_type, return_attention_weights=True)\n",
    "        else:\n",
    "            x = self.conv1(x, edge_index, edge_type)\n",
    "            att1 = None\n",
    "\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        if return_attention:\n",
    "            x, att2 = self.conv2(x, edge_index, edge_type, return_attention_weights=True)\n",
    "            return x, att1, att2\n",
    "\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "963664f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:43.237664Z",
     "start_time": "2026-02-18T08:21:43.220470Z"
    }
   },
   "source": [
    "def _rename_prefix(sd: dict, src: str, dst: str) -> dict:\n",
    "    out = {}\n",
    "    for k, v in sd.items():\n",
    "        if k.startswith(src + \".\"):\n",
    "            out[dst + k[len(src):]] = v\n",
    "        else:\n",
    "            out[k] = v\n",
    "    return out\n",
    "\n",
    "def _infer_scorer_in_mult(sd_sc: dict, dim: int):\n",
    "    key = None\n",
    "    for cand in [\"net.0.weight\", \"mlp.0.weight\"]:\n",
    "        if cand in sd_sc:\n",
    "            key = cand\n",
    "            break\n",
    "    if key is None:\n",
    "        for k in sd_sc.keys():\n",
    "            if k.endswith(\".0.weight\"):\n",
    "                key = k\n",
    "                break\n",
    "    if key is None:\n",
    "        return 2, 128\n",
    "    in_features = int(sd_sc[key].shape[1])\n",
    "    hidden = int(sd_sc[key].shape[0])\n",
    "    in_mult = max(1, in_features // int(dim))\n",
    "    return in_mult, hidden\n",
    "\n",
    "def _infer_gat_heads(sd_enc: dict, dim: int):\n",
    "    # PyG: conv1.att_src shape = [1, heads, out_channels]\n",
    "    for k in [\"conv1.att_src\", \"conv1.att_dst\", \"conv1.att_l\", \"conv1.att\"]:\n",
    "        if k in sd_enc:\n",
    "            t = sd_enc[k]\n",
    "            return int(t.shape[1])  # âœ… heads\n",
    "\n",
    "    # fallback: bias length = heads*out_channels (concat=True)\n",
    "    if \"conv1.bias\" in sd_enc:\n",
    "        b = sd_enc[\"conv1.bias\"]\n",
    "        if b.numel() % int(dim) == 0:\n",
    "            return int(b.numel() // int(dim))\n",
    "\n",
    "    # fallback: lin rows = heads*out_channels\n",
    "    for k in [\"conv1.lin_src.weight\", \"conv1.lin.weight\", \"conv1.lin_l.weight\"]:\n",
    "        if k in sd_enc:\n",
    "            w = sd_enc[k]\n",
    "            if w.shape[0] % int(dim) == 0:\n",
    "                return int(w.shape[0] // int(dim))\n",
    "\n",
    "    return 2\n",
    "\n",
    "def _infer_rgcn_num_bases(sd_enc: dict):\n",
    "    if \"conv1.comp\" in sd_enc and \"conv1.weight\" in sd_enc:\n",
    "        return int(sd_enc[\"conv1.weight\"].shape[0])\n",
    "    return None\n",
    "\n",
    "def _infer_rgat_heads_bases(sd_enc: dict):\n",
    "    heads = None\n",
    "    if \"conv1.q\" in sd_enc:\n",
    "        heads = int(sd_enc[\"conv1.q\"].shape[1])\n",
    "    num_bases = int(sd_enc[\"conv1.basis\"].shape[0]) if \"conv1.basis\" in sd_enc else 8\n",
    "    return heads, num_bases\n",
    "\n",
    "def find_ckpt(models_dir: Path, model_name: str):\n",
    "    p = models_dir / f\"{model_name}.pt\"\n",
    "    if p.exists():\n",
    "        return p\n",
    "    cands = sorted(models_dir.glob(f\"*{model_name}*.pt\"))\n",
    "    return cands[0] if cands else None\n",
    "\n",
    "def load_model(model_name: str, cfg: dict, g: dict, models_dir: Path):\n",
    "    ckpt_path = find_ckpt(models_dir, model_name)\n",
    "    if ckpt_path is None:\n",
    "        return None, None, None, None\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    sd_enc = ckpt[\"encoder\"]\n",
    "    sd_sc  = ckpt[\"scorer\"]\n",
    "\n",
    "    dim = int(sd_enc[\"emb.weight\"].shape[1])\n",
    "    dropout = float(cfg[\"model\"].get(\"dropout\", 0.2))\n",
    "\n",
    "    if any(k.startswith(\"mlp.\") for k in sd_sc.keys()) and not any(k.startswith(\"net.\") for k in sd_sc.keys()):\n",
    "        sd_sc = _rename_prefix(sd_sc, \"mlp\", \"net\")\n",
    "\n",
    "    in_mult, hidden = _infer_scorer_in_mult(sd_sc, dim)\n",
    "\n",
    "    scorer = MLPLinkScorer(dim=dim, hidden=hidden, dropout=dropout, in_mult=in_mult)\n",
    "    scorer.load_state_dict(sd_sc, strict=True)\n",
    "\n",
    "    if model_name == \"gat\":\n",
    "        heads = _infer_gat_heads(sd_enc, dim)\n",
    "        encoder = GATEncoder(num_nodes=int(g[\"num_nodes\"]), dim=dim, heads=heads, dropout=dropout)\n",
    "        encoder.load_state_dict(sd_enc, strict=True)\n",
    "        return encoder, scorer, ckpt_path, {\"dim\": dim, \"heads\": heads, \"in_mult\": in_mult}\n",
    "\n",
    "    if model_name == \"rgcn\":\n",
    "        num_bases = _infer_rgcn_num_bases(sd_enc)\n",
    "        encoder = RGCNEncoder(num_nodes=int(g[\"num_nodes\"]), num_relations=int(g[\"num_relations\"]),\n",
    "                              dim=dim, dropout=dropout, num_bases=num_bases)\n",
    "        encoder.load_state_dict(sd_enc, strict=True)\n",
    "        return encoder, scorer, ckpt_path, {\"dim\": dim, \"num_bases\": num_bases, \"in_mult\": in_mult}\n",
    "\n",
    "    if model_name == \"rgat\":\n",
    "        heads, num_bases = _infer_rgat_heads_bases(sd_enc)\n",
    "        if heads is None:\n",
    "            heads = int(cfg[\"model\"].get(\"rgat_heads\", 2))\n",
    "        encoder = RGATEncoder(num_nodes=int(g[\"num_nodes\"]), num_relations=int(g[\"num_relations\"]),\n",
    "                              dim=dim, heads=heads, dropout=dropout, num_bases=num_bases)\n",
    "        encoder.load_state_dict(sd_enc, strict=True)\n",
    "        return encoder, scorer, ckpt_path, {\"dim\": dim, \"heads\": heads, \"num_bases\": num_bases, \"in_mult\": in_mult}\n",
    "\n",
    "    return None, None, None, None\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:43.609300Z",
     "start_time": "2026-02-18T08:21:43.246902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and cfg[\"train\"].get(\"use_cuda\", True) else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "models_to_try = [\"gat\", \"rgcn\", \"rgat\"]\n",
    "models = {}\n",
    "\n",
    "for name in models_to_try:\n",
    "    enc, sc, path, info = load_model(name, cfg, g, models_dir)\n",
    "    if enc is None:\n",
    "        print(f\"[{name}] not found / load failed -> skip\")\n",
    "        continue\n",
    "    enc.to(device).eval()\n",
    "    sc.to(device).eval()\n",
    "    models[name] = {\"encoder\": enc, \"scorer\": sc, \"path\": path, \"info\": info}\n",
    "    print(f\"[{name}] loaded:\", path.name, \"| info:\", info)\n",
    "\n",
    "if len(models) == 0:\n",
    "    raise RuntimeError(\"No models loaded. Check output/models/*.pt\")\n",
    "\n",
    "ei_train_d = ei_train.to(device)\n",
    "et_train_d = et_train.to(device)\n"
   ],
   "id": "04e03464",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "[gat] loaded: gat.pt | info: {'dim': 128, 'heads': 4, 'in_mult': 3}\n",
      "[rgcn] loaded: rgcn.pt | info: {'dim': 128, 'num_bases': 30, 'in_mult': 3}\n",
      "[rgat] loaded: rgat.pt | info: {'dim': 32, 'heads': 2, 'num_bases': 8, 'in_mult': 3}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "57751668",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:49.350981Z",
     "start_time": "2026-02-18T08:21:43.616558Z"
    }
   },
   "source": [
    "@torch.no_grad()\n",
    "def compute_z(model_name: str, encoder, ei, et):\n",
    "    if model_name == \"gat\":\n",
    "        return encoder(ei)\n",
    "    if model_name == \"rgcn\":\n",
    "        return encoder(ei, et)\n",
    "    if model_name == \"rgat\":\n",
    "        return encoder(ei, et, return_attention=False)\n",
    "    return None\n",
    "\n",
    "Z = {}\n",
    "for name, m in models.items():\n",
    "    print(\"Computing embeddings for\", name, \"...\")\n",
    "    z = compute_z(name, m[\"encoder\"], ei_train_d, et_train_d)\n",
    "    Z[name] = z\n",
    "    print(\" z shape:\", tuple(z.shape))\n",
    "print(\"Embeddings ready.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for gat ...\n",
      " z shape: (37614, 128)\n",
      "Computing embeddings for rgcn ...\n",
      " z shape: (37614, 128)\n",
      "Computing embeddings for rgat ...\n",
      " z shape: (37614, 32)\n",
      "Embeddings ready.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "1c61acc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:49.365895Z",
     "start_time": "2026-02-18T08:21:49.360006Z"
    }
   },
   "source": [
    "def resolve_entity(query: str, prefix: str = None, topn: int = 10):\n",
    "    q = (query or \"\").strip()\n",
    "    if not q:\n",
    "        return []\n",
    "    q_low = q.lower()\n",
    "\n",
    "    if q in entity2id:\n",
    "        return [q]\n",
    "\n",
    "    if prefix is not None and not q.startswith(prefix):\n",
    "        cand = prefix + q\n",
    "        if cand in entity2id:\n",
    "            return [cand]\n",
    "\n",
    "    hits = []\n",
    "    for e in entity2id.keys():\n",
    "        if prefix is not None and not e.startswith(prefix):\n",
    "            continue\n",
    "        if q_low in e.lower():\n",
    "            hits.append(e)\n",
    "            if len(hits) >= topn:\n",
    "                break\n",
    "    if hits:\n",
    "        return hits\n",
    "\n",
    "    pool = [e for e in entity2id.keys() if (prefix is None or e.startswith(prefix))]\n",
    "    close = difflib.get_close_matches(q, pool, n=topn, cutoff=0.6)\n",
    "    return close\n",
    "\n",
    "def pick_first_id(query: str, prefix: str):\n",
    "    cands = resolve_entity(query, prefix=prefix, topn=10)\n",
    "    if not cands:\n",
    "        return None, []\n",
    "    return entity2id[cands[0]], cands\n",
    "\n",
    "COMPOUND_PREFIX = \"Compound::\"\n",
    "DISEASE_PREFIX  = \"Disease::\"\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "0d7868ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:49.398579Z",
     "start_time": "2026-02-18T08:21:49.384564Z"
    }
   },
   "source": [
    "compound_ids = [eid for e, eid in entity2id.items() if e.startswith(COMPOUND_PREFIX)]\n",
    "disease_ids  = [eid for e, eid in entity2id.items() if e.startswith(DISEASE_PREFIX)]\n",
    "print(\"num compounds:\", len(compound_ids))\n",
    "print(\"num diseases :\", len(disease_ids))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num compounds: 7974\n",
      "num diseases : 1867\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "14c1a34d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:49.412438Z",
     "start_time": "2026-02-18T08:21:49.406449Z"
    }
   },
   "source": [
    "@torch.no_grad()\n",
    "def score_pairs(model_name: str, head_ids: np.ndarray, tail_ids: np.ndarray, batch: int = 4096):\n",
    "    z = Z[model_name]\n",
    "    scorer = models[model_name][\"scorer\"]\n",
    "\n",
    "    head_ids = np.asarray(head_ids, dtype=np.int64)\n",
    "    tail_ids = np.asarray(tail_ids, dtype=np.int64)\n",
    "\n",
    "    out = []\n",
    "    for s in range(0, len(head_ids), batch):\n",
    "        h = torch.tensor(head_ids[s:s+batch], dtype=torch.long, device=device)\n",
    "        t = torch.tensor(tail_ids[s:s+batch], dtype=torch.long, device=device)\n",
    "        logits = scorer(z, h, t)\n",
    "        out.append(logits.detach().cpu().numpy())\n",
    "    logits = np.concatenate(out, axis=0)\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    return logits, probs\n",
    "\n",
    "def pretty_entity(eid: int):\n",
    "    return id2entity.get(str(int(eid)), f\"ent_{eid}\")\n",
    "\n",
    "def pretty_relation(rid: int):\n",
    "    return id2relation.get(str(int(rid)), f\"rel_{rid}\")\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "5926599c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:49.425840Z",
     "start_time": "2026-02-18T08:21:49.418901Z"
    }
   },
   "source": [
    "def shortest_path_with_rel(src: int, dst: int, max_hops: int = 3):\n",
    "    src = int(src); dst = int(dst)\n",
    "    if src == dst:\n",
    "        return []\n",
    "    prev = {src: None}\n",
    "    q = deque([(src, 0)])\n",
    "    while q:\n",
    "        u, d = q.popleft()\n",
    "        if d >= max_hops:\n",
    "            continue\n",
    "        for v, r in adj[u]:\n",
    "            if v in prev:\n",
    "                continue\n",
    "            prev[v] = (u, r)\n",
    "            if v == dst:\n",
    "                path = []\n",
    "                cur = dst\n",
    "                while cur != src:\n",
    "                    pu, pr = prev[cur]\n",
    "                    path.append((pu, pr, cur))\n",
    "                    cur = pu\n",
    "                path.reverse()\n",
    "                return path\n",
    "            q.append((v, d+1))\n",
    "    return None\n",
    "\n",
    "def explain_pair(src: int, dst: int, max_hops: int = 3):\n",
    "    path = shortest_path_with_rel(src, dst, max_hops=max_hops)\n",
    "    if path is None:\n",
    "        print(f\"No directed path found within {max_hops} hops.\")\n",
    "        return\n",
    "    if len(path) == 0:\n",
    "        print(\"Same node.\")\n",
    "        return\n",
    "    print(\"Path:\")\n",
    "    for u, r, v in path:\n",
    "        print(f\"  {pretty_entity(u)}  --[{pretty_relation(r)}]-->  {pretty_entity(v)}\")\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "5281010b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:49.437993Z",
     "start_time": "2026-02-18T08:21:49.432390Z"
    }
   },
   "source": [
    "def recommend_drugs_for_disease(disease_query: str, top_k: int = 20, model_name: str = \"rgat\"):\n",
    "    if model_name not in models:\n",
    "        raise ValueError(f\"Model '{model_name}' not loaded. Available: {list(models.keys())}\")\n",
    "\n",
    "    disease_id, cands = pick_first_id(disease_query, DISEASE_PREFIX)\n",
    "    if disease_id is None:\n",
    "        print(\"Disease not found. suggestions:\", resolve_entity(disease_query, DISEASE_PREFIX, topn=10))\n",
    "        return None\n",
    "\n",
    "    heads = np.array(compound_ids, dtype=np.int64)\n",
    "    tails = np.full_like(heads, disease_id)\n",
    "\n",
    "    _, probs = score_pairs(model_name, heads, tails, batch=4096)\n",
    "\n",
    "    idx = np.argsort(-probs)[:top_k]\n",
    "    top_heads = heads[idx]\n",
    "    top_probs = probs[idx]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"compound_id\": top_heads,\n",
    "        \"compound\": [pretty_entity(i) for i in top_heads],\n",
    "        \"disease_id\": int(disease_id),\n",
    "        \"disease\": pretty_entity(disease_id),\n",
    "        f\"prob_{model_name}\": top_probs\n",
    "    })\n",
    "\n",
    "    stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_csv = queries_dir / f\"recommend_{model_name}_{stamp}.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    print(\"Disease resolved to:\", pretty_entity(disease_id))\n",
    "    print(\"Saved:\", out_csv)\n",
    "    return df\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "eb92b2ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:49.451224Z",
     "start_time": "2026-02-18T08:21:49.444760Z"
    }
   },
   "source": [
    "def test_drug_disease(drug_query: str, disease_query: str, max_hops: int = 3):\n",
    "    drug_id, drug_cands = pick_first_id(drug_query, COMPOUND_PREFIX)\n",
    "    if drug_id is None:\n",
    "        print(\"Drug/Compound not found. suggestions:\", resolve_entity(drug_query, COMPOUND_PREFIX, topn=10))\n",
    "        return None\n",
    "\n",
    "    disease_id, dis_cands = pick_first_id(disease_query, DISEASE_PREFIX)\n",
    "    if disease_id is None:\n",
    "        print(\"Disease not found. suggestions:\", resolve_entity(disease_query, DISEASE_PREFIX, topn=10))\n",
    "        return None\n",
    "\n",
    "    rows = []\n",
    "    for name in models.keys():\n",
    "        head = np.array([drug_id], dtype=np.int64)\n",
    "        tail = np.array([disease_id], dtype=np.int64)\n",
    "        logits, probs = score_pairs(name, head, tail, batch=1)\n",
    "        rows.append({\n",
    "            \"model\": name,\n",
    "            \"logit\": float(logits[0]),\n",
    "            \"prob\": float(probs[0]),\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(\"prob\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    print(\"Drug   :\", pretty_entity(drug_id))\n",
    "    print(\"Disease:\", pretty_entity(disease_id))\n",
    "    display(df)\n",
    "\n",
    "    print(\"\\n--- Path explanation (graph) ---\")\n",
    "    explain_pair(drug_id, disease_id, max_hops=max_hops)\n",
    "\n",
    "    stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_json = queries_dir / f\"pair_{stamp}.json\"\n",
    "    payload = {\n",
    "        \"drug\": {\"query\": drug_query, \"id\": int(drug_id), \"entity\": pretty_entity(drug_id), \"candidates\": drug_cands},\n",
    "        \"disease\": {\"query\": disease_query, \"id\": int(disease_id), \"entity\": pretty_entity(disease_id), \"candidates\": dis_cands},\n",
    "        \"scores\": rows,\n",
    "        \"max_hops\": int(max_hops)\n",
    "    }\n",
    "    with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"Saved:\", out_json)\n",
    "    return df\n"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "673fb0e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T08:21:49.791680Z",
     "start_time": "2026-02-18T08:21:49.458884Z"
    }
   },
   "source": [
    "# --- Example 1: Recommend drugs for a disease ---\n",
    "df = recommend_drugs_for_disease(\"Disease::MESH:D014774\", top_k=20, model_name=\"rgat\")\n",
    "df\n",
    "\n",
    "# --- Example 2: Test one drug-disease pair on all available models + show a path ---\n",
    "res = test_drug_disease(\"Compound::DB01234\", \"Disease::MESH:D014774\", max_hops=3)\n",
    "res\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease resolved to: Disease::MESH:D017674\n",
      "Saved: D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\output\\queries\\recommend_rgat_20260218_115149.csv\n",
      "Drug   : Compound::DB01234\n",
      "Disease: Disease::MESH:D017674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  model      logit          prob\n",
       "0   gat  -3.338781  3.426448e-02\n",
       "1  rgat  -7.606811  4.968077e-04\n",
       "2  rgcn -18.566849  8.640125e-09"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>logit</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gat</td>\n",
       "      <td>-3.338781</td>\n",
       "      <td>3.426448e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rgat</td>\n",
       "      <td>-7.606811</td>\n",
       "      <td>4.968077e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rgcn</td>\n",
       "      <td>-18.566849</td>\n",
       "      <td>8.640125e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Path explanation (graph) ---\n",
      "No directed path found within 3 hops.\n",
      "Saved: D:\\Shiraz University\\HomeWorks\\Ostad Moosavi\\LinkPrediction\\output\\queries\\pair_20260218_115149.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  model      logit          prob\n",
       "0   gat  -3.338781  3.426448e-02\n",
       "1  rgat  -7.606811  4.968077e-04\n",
       "2  rgcn -18.566849  8.640125e-09"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>logit</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gat</td>\n",
       "      <td>-3.338781</td>\n",
       "      <td>3.426448e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rgat</td>\n",
       "      <td>-7.606811</td>\n",
       "      <td>4.968077e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rgcn</td>\n",
       "      <td>-18.566849</td>\n",
       "      <td>8.640125e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
